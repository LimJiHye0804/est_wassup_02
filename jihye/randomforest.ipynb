{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Titanic\n","## EDA\n","- RandomForest 와 ANN 돌리기 전 데이터를 분석 및 Vector 생성"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T02:19:13.683290Z","iopub.status.busy":"2023-11-14T02:19:13.682392Z","iopub.status.idle":"2023-11-14T02:19:14.144375Z","shell.execute_reply":"2023-11-14T02:19:14.142997Z","shell.execute_reply.started":"2023-11-14T02:19:13.683245Z"},"trusted":true},"outputs":[],"source":["import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns\n","from preprocess import *\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T02:19:14.147299Z","iopub.status.busy":"2023-11-14T02:19:14.146766Z","iopub.status.idle":"2023-11-14T02:19:14.188661Z","shell.execute_reply":"2023-11-14T02:19:14.187403Z","shell.execute_reply.started":"2023-11-14T02:19:14.147265Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","      <th>is_baby</th>\n","      <th>name_title</th>\n","      <th>family</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>Mr</td>\n","      <td>Single</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","      <td>0</td>\n","      <td>Mrs</td>\n","      <td>Single</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>Miss</td>\n","      <td>Single</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>Mrs</td>\n","      <td>Single</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>Mr</td>\n","      <td>Single</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived Pclass  \\\n","0            1         0      3   \n","1            2         1      1   \n","2            3         1      3   \n","3            4         1      1   \n","4            5         0      3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  is_baby name_title  family  \n","0      0         A/5 21171   7.2500   NaN        S        0         Mr  Single  \n","1      0          PC 17599  71.2833   C85        C        0        Mrs  Single  \n","2      0  STON/O2. 3101282   7.9250   NaN        S        0       Miss  Single  \n","3      0            113803  53.1000  C123        S        0        Mrs  Single  \n","4      0            373450   8.0500   NaN        S        0         Mr  Single  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# train_data = pd.read_csv('/Users/hj/Desktop/ESTCODE/train.csv')\n","# test_data = pd.read_csv('/Users/hj/Desktop/ESTCODE/test.csv')\n","\n","train_data = pd.read_csv('train.csv')\n","test_data = pd.read_csv('test.csv')\n","train_data=process(train_data)\n","test_data =process2(test_data)\n","train_data.head()\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T02:19:16.035978Z","iopub.status.busy":"2023-11-14T02:19:16.034869Z","iopub.status.idle":"2023-11-14T02:19:16.131605Z","shell.execute_reply":"2023-11-14T02:19:16.130102Z","shell.execute_reply.started":"2023-11-14T02:19:16.035939Z"},"trusted":true},"outputs":[{"data":{"text/plain":["((891, 14), (891, 1))"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["#데이터 처리하기, 모양 찍어보기\n","X_train = get_X(train_data,[\"Pclass\", \"Sex\", \"family\", \"is_baby\", \"name_title\"])\n","#모델 저장하기 \n","y_train = get_y(train_data)\n","X_test = get_X(test_data, [\"Pclass\", \"Sex\", \"family\", \"is_baby\", \"name_title\"])\n","\n","X_train = pd.DataFrame(X_train)\n","y_train = pd.DataFrame(y_train)\n","\n","\n","X_train.shape, y_train.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Random Forest"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T02:19:16.138357Z","iopub.status.busy":"2023-11-14T02:19:16.137931Z","iopub.status.idle":"2023-11-14T02:19:17.936752Z","shell.execute_reply":"2023-11-14T02:19:17.935412Z","shell.execute_reply.started":"2023-11-14T02:19:16.138323Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fit_time</th>\n","      <th>score_time</th>\n","      <th>test_accuracy</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.125854</td>\n","      <td>0.027152</td>\n","      <td>0.804469</td>\n","      <td>0.765625</td>\n","      <td>0.710145</td>\n","      <td>0.736842</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.121064</td>\n","      <td>0.032621</td>\n","      <td>0.831461</td>\n","      <td>0.771429</td>\n","      <td>0.794118</td>\n","      <td>0.782609</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.125207</td>\n","      <td>0.026264</td>\n","      <td>0.814607</td>\n","      <td>0.830189</td>\n","      <td>0.647059</td>\n","      <td>0.727273</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.133124</td>\n","      <td>0.025092</td>\n","      <td>0.803371</td>\n","      <td>0.789474</td>\n","      <td>0.661765</td>\n","      <td>0.720000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.115393</td>\n","      <td>0.024966</td>\n","      <td>0.842697</td>\n","      <td>0.847458</td>\n","      <td>0.724638</td>\n","      <td>0.781250</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.124129</td>\n","      <td>0.027219</td>\n","      <td>0.819321</td>\n","      <td>0.800835</td>\n","      <td>0.707545</td>\n","      <td>0.749595</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.006534</td>\n","      <td>0.003150</td>\n","      <td>0.017255</td>\n","      <td>0.036293</td>\n","      <td>0.058198</td>\n","      <td>0.030119</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n","0     0.125854    0.027152       0.804469        0.765625     0.710145   \n","1     0.121064    0.032621       0.831461        0.771429     0.794118   \n","2     0.125207    0.026264       0.814607        0.830189     0.647059   \n","3     0.133124    0.025092       0.803371        0.789474     0.661765   \n","4     0.115393    0.024966       0.842697        0.847458     0.724638   \n","mean  0.124129    0.027219       0.819321        0.800835     0.707545   \n","std   0.006534    0.003150       0.017255        0.036293     0.058198   \n","\n","       test_f1  \n","0     0.736842  \n","1     0.782609  \n","2     0.727273  \n","3     0.720000  \n","4     0.781250  \n","mean  0.749595  \n","std   0.030119  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#Random Forest\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import cross_validate\n","import warnings\n","warnings.simplefilter(\"ignore\")\n","\n","\n","scoring = ['accuracy', 'precision', 'recall', 'f1']\n","clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=2023)\n","scores = cross_validate(clf, X_train, y_train, scoring=scoring, cv=5)\n","scores_df = pd.DataFrame(scores)\n","pd.concat([scores_df, scores_df.apply(['mean', 'std'])])\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["accuarcy: 0.8268156424581006,f1_score: 0.7891156462585033\n","accuarcy: 0.7696629213483146,f1_score: 0.672\n","accuarcy: 0.8820224719101124,f1_score: 0.8141592920353982\n","accuarcy: 0.7808988764044944,f1_score: 0.7022900763358779\n","accuarcy: 0.7808988764044944,f1_score: 0.7194244604316548\n","0.8080597577051034\n","0.7393978950122868\n"]}],"source":["from sklearn.model_selection import StratifiedKFold, KFold\n","#from tqdm.auto import tqdm\n","from torch.utils.data import TensorDataset\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","clf2 = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2023)\n","\n","\n","kf = KFold(n_splits = 5, shuffle = True, random_state = 1111)\n","model_acc = []\n","model_f1 = []\n","# print(y_train.shape)\n","\n","ind = 0\n","for train_index, test_index in kf.split(X_train,y_train):\n","\t\t#나누기\n","    X_train_k, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n","    y_train_k, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n","\t\t\n","\t\t#모델 훈련하기\n","    clf2.fit(X_train_k, y_train_k)\n","\n","\t\t#예측값 담기\n","    y_pred = clf2.predict(X_val)\n","\n","    print(f'accuarcy: {accuracy_score(y_pred, y_val)},f1_score: {f1_score(y_pred, y_val)}')\n","    model_acc.append(accuracy_score(y_pred, y_val))\n","    model_f1.append(f1_score(y_pred, y_val))\n","\n","print(np.mean(model_acc))\n","print(np.mean(model_f1))"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n","       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n","       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n","       0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n","       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n","       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n","       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n","       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n","       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n","       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n","       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n","       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n","       1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n","       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n","       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n","       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n","       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n","       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = clf2.predict(X_test)\n","y_pred =y_pred.astype('int')\n","y_pred"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Your submission was successfully saved!\n"]}],"source":["\n","#submission\n","output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y_pred})\n","output.to_csv('submission.csv', index=False)\n","print(\"Your submission was successfully saved!\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# RandomForestRegressor"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["\"\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.metrics import mean_squared_error\\n\\n\\nscoring = ['accuracy','precision','recall','f1']\\nrf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\\n\\nmodel2_acc = []\\nmodel2_f1 = []\\n# print(y_train.shape)\\n\\nind = 0\\nfor train_index, test_index in kf.split(X_train, y_train):\\n\\t\\t#나누기\\n    X_train_k, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\\n    y_train_k, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\\n\\t\\t\\n\\t\\t#모델 훈련하기\\n    rf_regressor.fit(X_train_k, y_train_k)\\n\\n\\t\\t#예측값 담기\\n    y_pred = rf_regressor.predict(X_val)\\n\\n    print(f'f1_score: {f1_score(y_pred, y_val)}')\\n    #model2_acc.append(accuracy_score(y_pred, y_val))\\n    model2_f1.append(f1_score(y_pred, y_val))\\n#print(np.mean(model2_acc))\\nprint(np.mean(model2_f1))\\n\""]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","\n","scoring = ['accuracy','precision','recall','f1']\n","rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n","\n","model2_acc = []\n","model2_f1 = []\n","# print(y_train.shape)\n","\n","ind = 0\n","for train_index, test_index in kf.split(X_train, y_train):\n","\t\t#나누기\n","    X_train_k, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n","    y_train_k, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n","\t\t\n","\t\t#모델 훈련하기\n","    rf_regressor.fit(X_train_k, y_train_k)\n","\n","\t\t#예측값 담기\n","    y_pred = rf_regressor.predict(X_val)\n","\n","    print(f'f1_score: {f1_score(y_pred, y_val)}')\n","    #model2_acc.append(accuracy_score(y_pred, y_val))\n","    model2_f1.append(f1_score(y_pred, y_val))\n","#print(np.mean(model2_acc))\n","print(np.mean(model2_f1))\n","'''\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["'\\noutput2 = pd.DataFrame({\\'PassengerId\\': test_data.PassengerId, \\'Survived\\': y_pred})\\noutput2.to_csv(\\'submission.csv\\', index=False)\\nprint(\"Your submission was successfully saved!\")\\n'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","output2 = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y_pred})\n","output2.to_csv('submission.csv', index=False)\n","print(\"Your submission was successfully saved!\")\n","'''"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
