{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estsoft/miniconda3/envs/MathAI/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchmetrics\n",
    "from typing import Optional\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nn import *\n",
    "from preprocess import *\n",
    "from kfold import *\n",
    "from train import train_one_epoch\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "#from get import get, prepro\n",
    "#from factory_model import factory_model, create_models, models_cv\n",
    "#from cv import CV\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/pre.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37399, 107) (37399, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\nplt.hist(y_trn_re, bins=\\'auto\\')\\nplt.title(\"Histogram of Resampled Target Variable\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = get_X(data)\n",
    "y = get_y(data)[:,np.newaxis]\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "\n",
    "#print(X.isnull().sum())\n",
    "device = torch.device('cpu')\n",
    "#print(X.shape,y.shape)\n",
    "\n",
    "X_trn, X_test, y_trn, y_test = split2(X,y)\n",
    "\n",
    "#SMOTE 사용하기\n",
    "sm = RandomOverSampler(random_state=42)\n",
    "X_trn, y_trn = sm.fit_resample(X_trn, np.round(y_trn))\n",
    "\n",
    "X_trn, X_test, y_trn, y_test = torch.tensor(X_trn), torch.tensor(X_test),torch.tensor(y_trn), torch.tensor(y_test)\n",
    "X_trn, X_test, y_trn, y_test = X_trn.to(device), X_test.to(device), y_trn.to(device) , y_test.to(device)\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_trn_re, bins='auto')\n",
    "plt.title(\"Histogram of Resampled Target Variable\")\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([597870, 107]) torch.Size([597870]) torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(X_trn.shape, y_trn.shape , X_trn.dtype, y_trn.dtype)\n",
    "\n",
    "#Loader 올리기\n",
    "ds = TensorDataset(X_trn, y_trn.squeeze().to(torch.long))\n",
    "dl = DataLoader(ds, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN(X_trn.shape[-1],256).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([597870, 107])\n",
      "torch.Size([597870])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]/home/estsoft/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/estsoft/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([88])) that is different to the input size (torch.Size([88, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/estsoft/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([119574])) that is different to the input size (torch.Size([119574, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|          | 0/200 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:83] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 57191765904 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jihye/work/Dacon/test/test.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22455354536f667420284131362d345129227d/home/jihye/work/Dacon/test/test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m kfold_cross_validate(model,criterion\u001b[39m=\u001b[39;49mnn\u001b[39m.\u001b[39;49mMSELoss(), device\u001b[39m=\u001b[39;49mdevice, X_trn\u001b[39m=\u001b[39;49mX_trn, y_trn \u001b[39m=\u001b[39;49m y_trn, n_splits\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m , lr\u001b[39m=\u001b[39;49m\u001b[39m0.0001\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n",
      "File \u001b[0;32m~/work/Dacon/test/kfold.py:94\u001b[0m, in \u001b[0;36mkfold_cross_validate\u001b[0;34m(model, criterion, device, X_trn, y_trn, n_splits, lr, epochs)\u001b[0m\n\u001b[1;32m     92\u001b[0m mae, mse, rmse \u001b[39m=\u001b[39m MeanAbsoluteError()\u001b[39m.\u001b[39mto(device), MeanSquaredError()\u001b[39m.\u001b[39mto(device), MeanSquaredError(squared\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     93\u001b[0m loss \u001b[39m=\u001b[39m train_one_epoch(net, criterion, optimizer, dl, device)\n\u001b[0;32m---> 94\u001b[0m loss_val \u001b[39m=\u001b[39m evaluate(net, criterion, dl_val, device)\n\u001b[1;32m     95\u001b[0m mae_val, mse_val, rmse_val \u001b[39m=\u001b[39m mae\u001b[39m.\u001b[39mcompute()\u001b[39m.\u001b[39mitem(), mse\u001b[39m.\u001b[39mcompute()\u001b[39m.\u001b[39mitem(), rmse\u001b[39m.\u001b[39mcompute()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     96\u001b[0m pbar\u001b[39m.\u001b[39mset_postfix(trn_loss\u001b[39m=\u001b[39mloss, val_loss\u001b[39m=\u001b[39mloss_val)\n",
      "File \u001b[0;32m~/work/Dacon/test/kfold.py:38\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, criterion, data_loader, device, metric)\u001b[0m\n\u001b[1;32m     36\u001b[0m X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m output \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m---> 38\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m criterion(output, y)\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(y)\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m metric \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   metric\u001b[39m.\u001b[39mupdate(output, y)\n",
      "File \u001b[0;32m/home/estsoft/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/estsoft/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/estsoft/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/nn/modules/loss.py:535\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 535\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m/home/estsoft/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/nn/functional.py:3329\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3326\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m   3328\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbroadcast_tensors(\u001b[39minput\u001b[39m, target)\n\u001b[0;32m-> 3329\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:83] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 57191765904 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "kfold_cross_validate(model,criterion=nn.MSELoss(), device=device, X_trn=X_trn, y_trn = y_trn, n_splits=5 , lr=0.0001, epochs=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MathAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
